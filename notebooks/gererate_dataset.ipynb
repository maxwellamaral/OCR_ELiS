{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "doc-intro",
   "metadata": {},
   "source": [
    "# Geração do Dataset Sintético\\n\\n",
    "Este notebook é responsável por criar um dataset sintético de imagens de caracteres (visografemas) a partir da fonte ELiS. O processo inclui:\\n\\n",
    "- **Configuração de Parâmetros**: Define o tamanho das imagens, a quantidade de amostras por caractere e a divisão entre conjuntos de treino, validação e teste.\\n",
    "- **Extração de Caracteres da Fonte**: Identifica todos os caracteres mapeados na fonte `elis.ttf`.\\n",
    "- **Renderização e Augmentation**: Para cada caractere, gera uma imagem base e aplica uma série de transformações (rotação, zoom, ruído, etc.) para criar variações, aumentando a robustez do modelo de OCR.\\n",
    "- **Estruturação do Dataset**: Organiza as imagens geradas em uma estrutura de diretórios compatível com frameworks de aprendizado de máquina, como TensorFlow e PyTorch (`dataset/{train,validation,test}/{classe}`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-imports",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas\\n\\n",
    "Célula dedicada à importação de todas as bibliotecas necessárias para a geração do dataset, incluindo manipulação de arquivos (`os`, `pathlib`), processamento de imagens (`PIL`, `numpy`), data augmentation (`imgaug`) e análise de fontes (`fontTools`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\\n",
    "import shutil\\n",
    "import random\\n",
    "from PIL import Image, ImageFont, ImageDraw\\n",
    "import numpy as np\\n",
    "import imgaug as ia\\n",
    "import imgaug.augmenters as iaa\\n",
    "from fontTools.ttLib import TTFont\\n",
    "from pathlib import Path\\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-find-root",
   "metadata": {},
   "source": [
    "## Localização da Raiz do Projeto\\n\\n",
    "A função `find_project_root` localiza o diretório raiz do projeto para garantir que os caminhos para fontes e dados sejam resolvidos corretamente, independentemente de onde o notebook é executado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5d08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\n",
    "def find_project_root(markers=(\\"pyproject.toml\\", \\".git\\")) -> Path:\\n",
    "    '''\\n",
    "    Descobre a raiz do projeto subindo diretórios até encontrar um marcador.\\n",
    "\\n",
    "    Parâmetros:\\n",
    "        markers (tuple): Nomes de arquivos/pastas que indicam a raiz (ex.: \\"pyproject.toml\\", \\".git\\").\\n",
    "\\n",
    "    Retorna:\\n",
    "        pathlib.Path: Aponta para a raiz do projeto, ou o diretório atual como fallback.\\n",
    "    '''\\n",
    "    p = Path.cwd().resolve()\\n",
    "    for parent in [p, *p.parents]:\\n",
    "        if any((parent / m).exists() for m in markers):\\n",
    "            return parent\\n",
    "    return p\\n",
    "\\n",
    "ROOT = find_project_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-config",
   "metadata": {},
   "source": [
    "## Configurações Gerais\\n\\n",
    "Esta célula centraliza todos os parâmetros de configuração para a geração do dataset, como caminhos de diretórios, dimensões das imagens, tamanho da fonte e proporções para a divisão dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a56efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\\n",
    "DATA_DIR = ROOT / \\"data\\"\\n",
    "FONT_PATH = DATA_DIR / \\"external\\" / \\"elis.ttf\\"\\n",
    "OUTPUT_DIR = DATA_DIR / \\"raw\\" / \\"dataset\\"\\n",
    "\\n",
    "IMAGE_SIZE = (64, 64)\\n",
    "FONT_SIZE = 48\\n",
    "SAMPLES_PER_SYMBOL = 1000\\n",
    "\\n",
    "# Divisão do dataset\\n",
    "TRAIN_RATIO = 0.7\\n",
    "VALIDATION_RATIO = 0.15\\n",
    "#TEST_RATIO será o restante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-load-font-and-count",
   "metadata": {},
   "source": [
    "## Análise da Fonte e Extração de Caracteres\\n\\n",
    "Carrega a fonte `elis.ttf`, conta o número total de glifos e extrai os codepoints Unicode que serão usados como classes no dataset. Cada codepoint é convertido para o formato `U+XXXX`, que nomeará as pastas de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87868e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de glifos na fonte: 149\\n"
     ]
    }
   ],
   "source": [
    "font = TTFont(FONT_PATH)\\n",
    "\\n",
    "# número de glifos (glyphs) definidos na fonte\\n",
    "# Glifos são as formas visuais — os desenhos reais dentro da fonte.\\n",
    "# Ex.: um “a” romano, uma variante cursiva, uma ligadura “ffi”, ou um acento separado são todos glifos.\\n",
    "# Contagem típica: inclui glifos de base, alternates, ligaduras, marcas, .notdef, etc.\\n",
    "\\n",
    "glyph_count = len(font.getGlyphOrder())\\n",
    "print(f'Número de glifos na fonte: {glyph_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8deff6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de codepoints únicos: 146\\n"
     ]
    }
   ],
   "source": [
    "# Cria a lista de codepoints (códigos Unicode) em hexadecimal para os glifos\\n",
    "codepoints = []\\n",
    "for table in font['cmap'].tables:\\n",
    "    if table.isUnicode():\\n",
    "        codepoints.extend(table.cmap.keys())\\n",
    "codepoints = list(set(codepoints))  # Remove duplicatas\\n",
    "print(f'Número de codepoints únicos: {len(codepoints)}')\\n",
    "\\n",
    "CLASS_NAMES = [f'U+{cp:04X}' for cp in codepoints]\\n",
    "\\n",
    "# Tenta fechar a fonte\\n",
    "try:\\n",
    "    font.close()\\n",
    "except Exception:\\n",
    "    pass\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-augmentation",
   "metadata": {},
   "source": [
    "## Definição de Augmentations\\n\\n",
    "Configura uma sequência de transformações de imagem (`augmentation`) com a biblioteca `imgaug`. Essas transformações, como zoom, rotação, desfoque e ruído, são aplicadas aleatoriamente às imagens base para criar um dataset mais variado e robusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86596843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definição das Augmentations com imgaug ---\\n",
    "# Define uma sequência de transformações a serem aplicadas\\n",
    "augmentation_seq = iaa.Sequential(\\n",
    "    [\\n",
    "        iaa.Affine(\\n",
    "            scale={\\"x\\": (0.8, 1.2), \\"y\\": (0.8, 1.2)},  # Zoom de 80% a 120%\\n",
    "            translate_percent={\\"x\\": (-0.1, 0.1), \\"y\\": (-0.1, 0.1)},  # Translação\\n",
    "            rotate=(-15, 15),  # Rotação de -15 a 15 graus\\n",
    "            shear=(-8, 8),  # Cisalhamento\\n",
    "            cval=255,  # Cor de fundo branco\\n",
    "            mode='constant',\\n",
    "        ),\\n",
    "        # iaa.Multiply((0.7, 1.3), per_channel=0.2),         # Altera o brilho\\n",
    "        iaa.Multiply((0.85, 1.15), per_channel=0.2),  # Reduz variação para não escurecer muito\\n",
    "        iaa.GaussianBlur(sigma=(0, 0.8)),  # Desfoque Gaussiano\\n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.03 * 255), per_channel=0.5),  # Ruído\\n",
    "    ],\\n",
    "    random_order=True,\\n",
    ")  # Aplica as transformações em ordem aleatória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-render-function-2",
   "metadata": {},
   "source": [
    "## Funções de Geração de Imagem\\n\\n",
    "Duas funções auxiliares são definidas:\\n\\n",
    "- `render_glyph_bitmap`: Renderiza um glifo em uma imagem PIL, centralizando-o. (Esta é uma versão melhorada da função do notebook anterior).\\n",
    "- `create_base_image`: Utiliza a função anterior para gerar a imagem de um caractere, redimensiona para o tamanho final do dataset e a converte para um array NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0768d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\\n",
    "from typing import Union\\n",
    "\\n",
    "def render_glyph_bitmap(\\n",
    "    font_path: Union[str, os.PathLike],\\n",
    "    char_or_codepoint: Union[int, str],\\n",
    "    image_size: int = 256,\\n",
    "    font_px: int | None = None,\\n",
    "    bgcolor: int = 255,\\n",
    "    fgcolor: int = 0,\\n",
    ") -> Image.Image:\\n",
    "    '''\\n",
    "    Renderiza um glifo de uma fonte TTF/OTF em uma imagem quadrada em escala de cinza (modo 'L').\\n",
    "\\n",
    "    Parâmetros:\\n",
    "        font_path: caminho para o arquivo de fonte (TTF/OTF). Aceita str ou PathLike.\\n",
    "        char_or_codepoint: inteiro Unicode (ex.: 0x0041) ou caractere único (ex.: \\"A\\").\\n",
    "        image_size: lado do quadrado de saída, em pixels (ex.: 256).\\n",
    "        font_px: tamanho do corpo da fonte em pixels; se None, usa 80% de image_size.\\n",
    "        bgcolor: cor de fundo (0..255), padrão 255 (branco).\\n",
    "        fgcolor: cor do glifo (0..255), padrão 0 (preto).\\n",
    "\\n",
    "    Retorna:\\n",
    "        PIL.Image.Image: No modo 'L' com o glifo centralizado no canvas.\\n",
    "\\n",
    "    Erros:\\n",
    "        FileNotFoundError: se o arquivo de fonte não existir.\\n",
    "        ValueError: se for passada string com mais de um caractere.\\n",
    "        OSError: se a fonte não puder ser carregada pelo Pillow.\\n",
    "\\n",
    "    Observações:\\n",
    "        - Centraliza o glifo usando getbbox para calcular deslocamento exato.\\n",
    "        - Se a fonte não tiver o glifo específico, a renderização pode recair em fallback da fonte.\\n",
    "    '''\\n",
    "    # Normaliza o caminho e valida existência\\n",
    "    font_path = str(font_path)\\n",
    "    if not os.path.exists(font_path):\\n",
    "        raise FileNotFoundError(font_path)\\n",
    "\\n",
    "    # Normaliza o caractere\\n",
    "    if isinstance(char_or_codepoint, int):\\n",
    "        ch = chr(char_or_codepoint)\\n",
    "    else:\\n",
    "        ch = str(char_or_codepoint)\\n",
    "        if len(ch) != 1:\\n",
    "            raise ValueError(\\"Quando str, 'char_or_codepoint' deve ter exatamente 1 caractere.\\")\\n",
    "\\n",
    "    # Define tamanho da fonte se não informado\\n",
    "    if font_px is None:\\n",
    "        font_px = int(image_size * 0.8)\\n",
    "\\n",
    "    # Carrega a fonte e renderiza centralizado\\n",
    "    font = ImageFont.truetype(font_path, size=font_px)\\n",
    "    img = Image.new('L', (image_size, image_size), color=bgcolor)\\n",
    "    draw = ImageDraw.Draw(img)\\n",
    "\\n",
    "    bbox = font.getbbox(ch)  # (x0, y0, x1, y1) relativo à origem\\n",
    "    w = bbox[2] - bbox[0]\\n",
    "    h = bbox[3] - bbox[1]\\n",
    "    x = (image_size - w) // 2 - bbox[0]\\n",
    "    y = (image_size - h) // 2 - bbox[1]\\n",
    "\\n",
    "    draw.text((x, y), ch, font=font, fill=fgcolor)\\n",
    "\\n",
    "    # FreeTypeFont não exige close; mantendo try/except por compatibilidade\\n",
    "    try:\\n",
    "        font.close()\\n",
    "    except Exception:\\n",
    "        pass\\n",
    "\\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_image(symbol: int) -> np.ndarray:\\n",
    "    '''\\n",
    "    Renderiza um símbolo e o redimensiona para o tamanho padrão do dataset.\\n",
    "\\n",
    "    Esta função utiliza `render_glyph_bitmap` para criar uma imagem de alta resolução\\n",
    "    de um glifo e, em seguida, a redimensiona para o `IMAGE_SIZE` configurado,\\n",
    "    usando um filtro de alta qualidade para preservar detalhes.\\n",
    "\\n",
    "    Args:\\n",
    "        symbol (int): O codepoint Unicode do caractere a ser renderizado.\\n",
    "\\n",
    "    Returns:\\n",
    "        np.ndarray: A imagem do glifo como um array NumPy em escala de cinza.\\n",
    "    '''\\n",
    "    # Usa a configuração global FONT_PATH (normalizada para str)\\n",
    "    image = render_glyph_bitmap(str(FONT_PATH), symbol, image_size=256)\\n",
    "\\n",
    "    # Redimensiona com o melhor filtro disponível\\n",
    "    try:\\n",
    "        resample_filter = Image.Resampling.LANCZOS  # Pillow >= 9.1\\n",
    "    except AttributeError:\\n",
    "        resample_filter = Image.LANCZOS             # Pillow < 9.1\\n",
    "\\n",
    "    image = image.resize(IMAGE_SIZE, resample=resample_filter)\\n",
    "    return np.array(image, copy=False)\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c551e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\\n",
    "# create_base_image(0x0030)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-setup-dirs",
   "metadata": {},
   "source": [
    "## Preparação dos Diretórios de Saída\\n\\n",
    "A função `setup_directories` prepara a estrutura de pastas para o dataset. Ela limpa o diretório de saída principal para evitar dados antigos e cria as subpastas `train`, `validation` e `test`, cada uma contendo diretórios para todas as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f70d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories() -> None:\\n",
    "    '''\\n",
    "    Limpa e recria a estrutura de diretórios para o dataset.\\n",
    "\\n",
    "    A estrutura final será `OUTPUT_DIR/{train,validation,test}/U+XXXX`, onde `U+XXXX`\\n",
    "    corresponde a cada classe (caractere) a ser gerada.\\n",
    "\\n",
    "    Atenção: Esta função deleta o diretório `OUTPUT_DIR` se ele já existir.\\n",
    "    '''\\n",
    "    if OUTPUT_DIR.exists():\\n",
    "        shutil.rmtree(OUTPUT_DIR)\\n",
    "\\n",
    "    for split in ['train', 'validation', 'test']:\\n",
    "        for class_name in CLASS_NAMES:\\n",
    "            (OUTPUT_DIR / split / class_name).mkdir(parents=True, exist_ok=True)\\n",
    "\\n",
    "    print(\\"Estrutura de diretórios criada com sucesso.\\")\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-generate-dataset",
   "metadata": {},
   "source": [
    "## Geração e Salvamento do Dataset\\n\\n",
    "Este é o loop principal do notebook. Ele itera sobre cada caractere (codepoint), gera a imagem base, aplica as augmentations definidas para criar o número desejado de amostras e salva cada imagem no diretório correspondente (treino, validação ou teste) de forma aleatória, respeitando as proporções definidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb693c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FONT_PATH):\\n",
    "    raise FileNotFoundError(f'Fonte não encontrada: {FONT_PATH}')\\n",
    "    #return\\n",
    "\\n",
    "setup_directories()\\n",
    "\\n",
    "for i, symbol in enumerate(tqdm(codepoints, desc=\\"Gerando dataset\\")):\\n",
    "    class_name = f'U+{symbol:04X}'\\n",
    "    base_image = create_base_image(symbol)\\n",
    "\\n",
    "    for j in range(SAMPLES_PER_SYMBOL):\\n",
    "        augmented_image = augmentation_seq(image=base_image)\\n",
    "        img_pil = Image.fromarray(augmented_image)\\n",
    "\\n",
    "        # Decide a divisão do dataset\\n",
    "        rand_val = random.random()\\n",
    "        if rand_val < TRAIN_RATIO:\\n",
    "            split = 'train'\\n",
    "        elif rand_val < TRAIN_RATIO + VALIDATION_RATIO:\\n",
    "            split = 'validation'\\n",
    "        else:\\n",
    "            split = 'test'\\n",
    "\\n",
    "        img_filename = os.path.join(OUTPUT_DIR, split, class_name, f'{class_name}_{j:04d}.png')\\n",
    "        img_pil.save(img_filename)\\n",
    "print(\\"Dataset gerado com sucesso.\\")\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}