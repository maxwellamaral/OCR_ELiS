{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificação de Ambiente de GPU\n",
    "\n",
    "Este notebook serve como um script de diagnóstico para verificar a configuração do ambiente de computação acelerada por GPU. Ele examina a disponibilidade e a configuração do TensorFlow, PyTorch e dos drivers NVIDIA.\n",
    "\n",
    "As verificações realizadas incluem:\n",
    "1.  **Versões de Python e Frameworks**: Exibe as versões instaladas do Python, TensorFlow e PyTorch.\n",
    "2.  **Detecção de GPU pelo TensorFlow**: Verifica se o TensorFlow consegue detectar e listar as GPUs físicas disponíveis e com qual versão do CUDA/cuDNN foi construído.\n",
    "3.  **Detecção de GPU pelo PyTorch**: Confirma se o PyTorch pode acessar o CUDA, lista as GPUs visíveis e mostra suas propriedades, como nome e memória.\n",
    "4.  **Status do Driver NVIDIA**: Executa o comando `nvidia-smi` para obter informações diretamente do driver da NVIDIA, incluindo o nome da GPU, a versão do driver e o uso atual.\n",
    "\n",
    "O objetivo é fornecer um relatório abrangente que ajude a diagnosticar rapidamente problemas comuns de configuração, como drivers incompatíveis, instalações incorretas de frameworks ou problemas de visibilidade da GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b6fbd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import torch\n",
    "import textwrap\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação da Versão do Python\n",
    "\n",
    "Exibe a versão do interpretador Python que está executando o notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcf942ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python:\", sys.version.splitlines()[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação do TensorFlow e CUDA/cuDNN\n",
    "\n",
    "Esta célula verifica a instalação do TensorFlow. Ela tenta importar a biblioteca, imprime a versão e, o mais importante, verifica se o TensorFlow consegue detectar as GPUs físicas. Também exibe as versões do CUDA e do cuDNN com as quais o TensorFlow foi construído, o que é crucial para a compatibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5e53b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"TensorFlow:\", tf.__version__)\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(\"  GPUs detectadas por TensorFlow:\", len(gpus))\n",
    "    for i, g in enumerate(gpus):\n",
    "        print(f\"    [{i}] {g}\")\n",
    "    try:\n",
    "        print(\"  TF built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "    except Exception:\n",
    "        # fallback: algumas versões não têm is_built_with_cuda\n",
    "        print(\"  TF built with CUDA: (não disponível nesta versão do TF)\")\n",
    "except Exception as e:\n",
    "    print(\"TensorFlow: não disponível ou erro ao importar:\", e)\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "build = tf.sysconfig.get_build_info()\n",
    "print(\"Versão CUDA:\", build.get(\"cuda_version\", \"desconhecida\"))\n",
    "print(\"Versão cuDNN:\", build.get(\"cudnn_version\", \"desconhecida\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação do PyTorch e CUDA\n",
    "\n",
    "Semelhante à verificação do TensorFlow, esta célula verifica a instalação do PyTorch. Ela confirma se o PyTorch foi instalado com suporte a CUDA (`torch.cuda.is_available()`), conta o número de GPUs detectadas e lista o nome e a memória de cada uma. A versão do CUDA com a qual o PyTorch foi compilado também é exibida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0087ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch:\", torch.__version__)\n",
    "    print(\"  torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "    try:\n",
    "        count = torch.cuda.device_count()\n",
    "        print(\"  GPUs detectadas por PyTorch:\", count)\n",
    "        for i in range(count):\n",
    "            print(f\"    [{i}] {torch.cuda.get_device_name(i)}\")\n",
    "            mem = torch.cuda.get_device_properties(i).total_memory\n",
    "            print(f\"      Memória total (bytes): {mem}\")\n",
    "    except Exception as e:\n",
    "        print(\"  Erro ao obter detalhes da GPU via PyTorch:\", e)\n",
    "    print(\"  CUDA (compilado):\", torch.version.cuda)\n",
    "except Exception as e:\n",
    "    print(\"PyTorch: não disponível ou erro ao importar:\", e)\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação do Driver NVIDIA com `nvidia-smi`\n",
    "\n",
    "Esta célula interage diretamente com o sistema operacional para executar o comando `nvidia-smi`, a ferramenta de linha de comando da NVIDIA. Isso fornece uma \"fonte da verdade\" sobre o que o driver da NVIDIA está relatando, incluindo as GPUs detectadas, a versão do driver e a memória total. É uma forma independente de verificar a configuração do hardware, sem depender dos frameworks de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1e64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(cmd: str) -> str | None:\n",
    "    \"\"\"Executa um comando de shell e retorna sua saída como uma string.\n",
    "\n",
    "    Args:\n",
    "        cmd (str): O comando a ser executado.\n",
    "\n",
    "    Returns:\n",
    "        str | None: A saída do comando decodificada como UTF-8 ou None se o comando falhar.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        out = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n",
    "        return out.decode('utf-8', errors='ignore')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return None\n",
    "\n",
    "nvsmi = run_cmd(\"nvidia-smi -L\")\n",
    "if nvsmi:\n",
    "    print(\"nvidia-smi -L (GPUs detectadas):\")\n",
    "    print(nvsmi.strip())\n",
    "    print(\"nvidia-smi (sumário):\")\n",
    "    print(run_cmd(\"nvidia-smi --query-gpu=name,index,memory.total,driver_version --format=csv\"))\n",
    "else:\n",
    "    print(\"nvidia-smi não encontrado ou não respondeu. Pode não haver driver NVIDIA instalado ou o utilitário não está no PATH.\")\n",
    "    # tentar informações do kernel\n",
    "    mod = run_cmd(\"lsmod | grep nvidia || true\")\n",
    "    print(\"Módulos nvidia carregados (lsmod | grep nvidia):\")\n",
    "    print(mod or \"(nenhum)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de Uso de Dispositivo em PyTorch\n",
    "\n",
    "Demonstra a prática padrão no PyTorch para selecionar a GPU (se disponível) ou recorrer à CPU. O objeto `device` é então usado para mover tensores e modelos para o hardware apropriado durante o treinamento ou inferência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e3b285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# cria device explicitamente (assumindo que cuda está disponível)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relatório de Diagnóstico Completo\n",
    "\n",
    "Esta célula final combina todas as verificações anteriores em um único script de diagnóstico. Ele gera um relatório claro e formatado com informações do Python, TensorFlow, PyTorch e `nvidia-smi`. Além disso, inclui dicas de solução de problemas para ajudar a interpretar os resultados e corrigir problemas comuns de configuração de GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22affb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula: verificação completa de GPU (TensorFlow, PyTorch, nvidia-smi)\n",
    "def hr(title: str = \"\") -> None:\n",
    "    \"\"\"Imprime uma linha horizontal com um título opcional para formatar a saída.\n",
    "\n",
    "    Args:\n",
    "        title (str, optional): O título a ser exibido acima da linha. O padrão é \"\".\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    if title:\n",
    "        print(title)\n",
    "        print(\"-\"*len(title))\n",
    "\n",
    "def human_bytes(n: int) -> str:\n",
    "    \"\"\"Converte um número de bytes em um formato legível por humanos (KB, MB, GB).\n",
    "\n",
    "    Args:\n",
    "        n (int): O número de bytes.\n",
    "\n",
    "    Returns:\n",
    "        str: A representação da string formatada.\n",
    "    \"\"\"\n",
    "    for unit in ['B','KB','MB','GB','TB']:\n",
    "        if abs(n) < 1024.0:\n",
    "            return f\"{n:3.1f}{unit}\"\n",
    "        n /= 1024.0\n",
    "    return f\"{n:.1f}PB\"\n",
    "\n",
    "print(f\"Relatório gerado em: {datetime.now().isoformat(sep=' ', timespec='seconds')}\")\n",
    "hr(\"Python / Ambiente\")\n",
    "print(\"Python:\", sys.version.splitlines()[0])\n",
    "\n",
    "# TensorFlow\n",
    "hr(\"TensorFlow\")\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"tensorflow:\", tf.__version__)\n",
    "    try:\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        print(\"  GPUs detectadas por TensorFlow:\", len(gpus))\n",
    "        for i, g in enumerate(gpus):\n",
    "            print(f\"    [{i}] {g}\")\n",
    "    except Exception as e:\n",
    "        print(\"  Erro ao listar GPUs no TF:\", e)\n",
    "    try:\n",
    "        built_cuda = tf.test.is_built_with_cuda()\n",
    "        print(\"  TF built with CUDA:\", built_cuda)\n",
    "    except Exception:\n",
    "        # fallback se função não existir\n",
    "        build = tf.sysconfig.get_build_info()\n",
    "        print(\"  TF build info (cuda/cudnn):\",\n",
    "              f\"cuda={build.get('cuda_version','?')}, cudnn={build.get('cudnn_version','?')}\")\n",
    "except Exception as e:\n",
    "    print(\"TensorFlow não disponível / erro ao importar:\", str(e))\n",
    "\n",
    "# PyTorch\n",
    "hr(\"PyTorch\")\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch:\", torch.__version__)\n",
    "    cuda_avail = torch.cuda.is_available()\n",
    "    print(\"  torch.cuda.is_available():\", cuda_avail)\n",
    "    try:\n",
    "        dev_count = torch.cuda.device_count()\n",
    "        print(\"  GPUs detectadas por PyTorch:\", dev_count)\n",
    "        for i in range(dev_count):\n",
    "            try:\n",
    "                name = torch.cuda.get_device_name(i)\n",
    "            except Exception:\n",
    "                name = \"(nome indisponível)\"\n",
    "            try:\n",
    "                props = torch.cuda.get_device_properties(i)\n",
    "                mem = props.total_memory\n",
    "            except Exception:\n",
    "                mem = None\n",
    "            print(f\"    [{i}] {name}\")\n",
    "            if mem:\n",
    "                print(f\"       Memória total: {human_bytes(mem)}\")\n",
    "    except Exception as e:\n",
    "        print(\"  Erro ao obter detalhes via PyTorch:\", e)\n",
    "    try:\n",
    "        print(\"  CUDA (compilado):\", torch.version.cuda)\n",
    "    except Exception:\n",
    "        pass\n",
    "except Exception as e:\n",
    "    print(\"PyTorch não disponível / erro ao importar:\", str(e))\n",
    "\n",
    "# nvidia-smi / driver\n",
    "hr(\"nvidia-smi / Driver\")\n",
    "nvsmi_path = run_cmd(\"which nvidia-smi\")\n",
    "if nvsmi_path:\n",
    "    print(\"nvidia-smi encontrado em:\", nvsmi_path)\n",
    "    print(\"\\nSaída: nvidia-smi -L\")\n",
    "    print(run_cmd(\"nvidia-smi -L\") or \"(vazio)\")\n",
    "    print(\"\\nSumário (name,index,memory.total,driver_version):\")\n",
    "    print(run_cmd(\"nvidia-smi --query-gpu=name,index,memory.total,driver_version --format=csv\") or \"(não retornou)\")\n",
    "    print(\"\\nUtilização / status (top):\")\n",
    "    print(run_cmd(\"nvidia-smi --query-gpu=index,name,temperature.gpu,utilization.gpu,utilization.memory --format=csv,nounits\") or \"(não retornou)\")\n",
    "else:\n",
    "    print(\"nvidia-smi não encontrado no PATH. Pode não haver driver NVIDIA instalado ou utilitário não está disponível.\")\n",
    "    # tenta checar módulos do kernel\n",
    "    mod = run_cmd(\"lsmod | grep -i nvidia || true\")\n",
    "    print(\"\\nMódulos nvidia carregados (lsmod | grep -i nvidia):\")\n",
    "    print(mod or \"(nenhum)\")\n",
    "\n",
    "# Dicas rápidas\n",
    "hr(\"Dicas rápidas / interpretação\")\n",
    "print(textwrap.dedent(\"\"\"\n",
    "- Se 'nvidia-smi' não existir: driver NVIDIA ausente; instale driver apropriado para sua distribuição.\n",
    "- Se 'nvidia-smi' mostrar GPUs, mas torch.cuda.is_available() for False:\n",
    "  - possivelmente PyTorch foi instalado sem suporte CUDA ou há incompatibilidade entre driver e runtime CUDA.\n",
    "  - solução rápida: usar conda e instalar pytorch + pytorch-cuda compatível com sua versão de driver.\n",
    "- Se TensorFlow não vê GPU: verifique se instalou a versão GPU (ou compatível) do TensorFlow e a compatibilidade CUDA/cuDNN.\n",
    "- Em Docker: rode com '--gpus all' e instale 'nvidia-docker2' / 'nvidia-container-toolkit'.\n",
    "- Se quiser, cole a saída completa desta célula aqui que eu indico os comandos exatos para instalar drivers / bibliotecas.\n",
    "\"\"\"))\n",
    "hr(\"Fim do relatório\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
